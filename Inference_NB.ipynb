{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from numpy import random\n",
    "\n",
    "from models.experimental import attempt_load\n",
    "from utils.datasets import LoadStreams, LoadImages\n",
    "from utils.general import check_img_size, non_max_suppression, apply_classifier, scale_coords, xyxy2xywh, \\\n",
    "    plot_one_box, strip_optimizer, set_logging, increment_dir\n",
    "from utils.torch_utils import select_device, load_classifier, time_synchronized\n",
    "\n",
    "\n",
    "def detect(source):\n",
    "    device = select_device('')\n",
    "    half = device.type != 'cpu'  # half precision only supported on CUDA\n",
    "\n",
    "    # Load models\n",
    "    model = attempt_load(\"yolov5x.pt\", map_location=device)  # load FP32 model\n",
    "    imgsz = check_img_size(640, s=model.stride.max())  # check img_size\n",
    "    if half:\n",
    "        model.half()  # to FP16\n",
    "\n",
    "\n",
    "    # Set Dataloader\n",
    "    vid_path, vid_writer = None, None\n",
    "    view_img = True\n",
    "    cudnn.benchmark = True  # set True to speed up constant image size inference\n",
    "    dataset = LoadStreams(source, img_size=imgsz)\n",
    "\n",
    "    # Get names and colors\n",
    "    names = model.module.names if hasattr(model, 'module') else model.names\n",
    "    colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(names))]\n",
    "\n",
    "    # Run inference\n",
    "    img = torch.zeros((1, 3, imgsz, imgsz), device=device)  # init img\n",
    "    _ = model(img.half() if half else img) if device.type != 'cpu' else None  # run once\n",
    "    for path, img, im0s, vid_cap in dataset:\n",
    "        img = torch.from_numpy(img).to(device)\n",
    "        img = img.half() if half else img.float()  # uint8 to fp16/32\n",
    "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "        if img.ndimension() == 3:\n",
    "            img = img.unsqueeze(0)\n",
    "\n",
    "        # Inference\n",
    "        t1 = time_synchronized()\n",
    "        pred = model(img, augment=\"store_true\")[0]\n",
    "\n",
    "        # Apply NMS\n",
    "        pred = non_max_suppression(pred, 0.25, 0.45, agnostic=\"store_true\")\n",
    "        t2 = time_synchronized()\n",
    "\n",
    "\n",
    "        # Process detections\n",
    "        for i, det in enumerate(pred):  # detections per image\n",
    "            p, s, im0 = Path(path[i]), '%g: ' % i, im0s[i].copy()\n",
    "\n",
    "            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
    "            if det is not None and len(det):\n",
    "                # Rescale boxes from img_size to im0 size\n",
    "                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
    "\n",
    "                # Write results\n",
    "                for *xyxy, conf, cls in reversed(det):\n",
    "                    x, y, w, h = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
    "                    x1, y1, x2, y2 = xyxy\n",
    "                    if names[int(cls)] == \"person\":\n",
    "                        cv2.rectangle(im0, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "\n",
    "            # Print time (inference + NMS)\n",
    "            # print('%sDone. (%.3fs)' % (s, t2 - t1))\n",
    "\n",
    "            # Stream results\n",
    "\n",
    "            cv2.imshow(str(i), im0)\n",
    "            if cv2.waitKey(1) == ord('q'):  # q to quit\n",
    "                raise StopIteration\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    source = [\"./data/videos/Video1.mp4\", \"./data/videos/Video2.mp4\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        detect(source)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
